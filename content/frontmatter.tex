% !TEX root = ms.tex

\chapter*{License}
\vspace{4cm}
\lipsum[1]

\chapter*{Acknowledgements}
\lipsum[2]



\chapter*{Abstract}
\textbf{[On Proccess]} The latest release of Large Language Models (LLMs) opens the door to novel
implementation of Artificial General Intelligence (AGI).  Beyond optimizing
machine learning models, AGI development requires cognitive structures that
enable LLMs to operate effectively in real-world applications. This report
introduces the \textbf{Execution-Cognition Machine} (ECM) as a theoretical
framework that decomposes AGI's design into an approximation problem involving
three key variables: \textbf{Execution Space}, \textbf{Cognition Space} and 
\textbf{Action Space}. As an approximation of this problem, we propose
\textsc{[SystemName]} as a framework for testing and developing AGIs
implementing multiple approaches at each layer. At last, we survey several
techniques, including Prompt Engineering, Exelent-Code, and Prompt Optimization,
to create an AGI agent that supports comprehensive user-AI interaction.

\todo{Incluir en el abstract mencion a la implementacion en RaspBerry,
y resultados}


\chapter*{Acronyms}
\begin{itemize}
    \item \textbf{AI}: Artificial Intelligence
    \item \textbf{AP}: Agent Protocol
    \item \textbf{$A_1$}: Execution Layer Algorithm
    \item \textbf{$A_2$}: Cognition Layer Algorithm
    \item \textbf{LLM}: Large Language Model
    \item \textbf{ECM}: Execution-Cognition Machine
    \item \textbf{AGI}: Artificial General Intelligence
    \item \textbf{RAG}: Retrieval Augmented Generation 
    \item \textbf{PMPA}: Profile-Memory-Plan-Action

\end{itemize}

\begingroup
\setlength{\parskip}{0pt}
\setlength{\parindent}{3pt}
\tableofcontents
\endgroup

