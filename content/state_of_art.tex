% !TEX root = ms.tex
\chapter{State of Art}
\section{IA Suave y Fuerte}

Para definir la Inteligencia Artificial \citet{searle1980minds} distingue dos
tipos de IA. La IA \emph{suave}\footnote{Nótese que aunque similares, es
importante no confundir IA suave con IA clásica.} hace referencia a un conjunto
de algoritmos o herramientas que aproximan una solucion a un problema
determinado utilizando estrategias basadas en analisis y reacción a traves de
múltiples estados. En contraste, la IA \emph{fuerte} esta caracterizada por
sus capacidades para entender de forma profunda, razonar y reaccionar a estados
impredecibles, adaptandose y aprendiendo a lo largo del proceso de resolución
del problema. 

Desde el diseño de las \emph{redes neuronales} en 1949, nuevas tecnicas para el 
desarrollo de IA fuerte han estado en auge. Aunque la IA fuerte muestra
propiedades aparentemente utópicas, muchos de los subproblemas que encierra su
diseño han fomentado la evolución de multiples sectores. Como ejemplo de esto,
el campo del aprendizaje automatic se ha expandido creando nuevos campos de
estudio como el aprendizaje profundo. Será este nuevo campo es el responsable de
la creación de los Modelos Grandes de Lenguaje (LLMs), donde modelos como
\textsc{GPT-4} (\citet{achiam2023gpt}), \textsc{Llama2} o
(\citet{touvron2023llama}), o \textsc{Gemini} (\citet{saeidnia2023welcome}) utilizan
el entrenamiento de millones de iteraciones sobre el conocimiento humano para recrear
propiedades emergentes como lo son el entendimiento del sentido comun, habilidades
de razonamiento y resolución de problemas, generación de respuestas con contexto, etc.
Estos modelos aun estan en etapa de desarrollo, donde el objetivo apunta a
propiedades como la multi-modalidad\footnote{(Capacidad para trabajar con
multiples tipos de entrada, como audios o imagenes.)}, reconocimiento de
patrones y/o explicabilidad, acercando a estos modelos a la integración de agentes
cognitivos completos.

\todo{En el parrafo, menciono 3 ejemplos de LLMs del estado del arte: GPT4,
Llama2 y Gemini ¿Deberia explicar cada una por separado?}

\section{Agentes y Cognición}
\label{sec:agents_and_cognition}

Estandarizando la salida de los modelos, es posible conseguir que los LLMs sean
capaces de usar múltiples \emph{herramientas}. En el ámbito de la IA, las
herramientas son un conjunto de funciones o utilidades que permiten que el LLM
interactúe con su entorno. Gracias a esto, mientras que un LLM solo puede
generar una salida a partir de una consulta dada, los agentes traducen esas
salidas en acciones que modifican el mundo y, opcionalmente, la propia
configuración del agente.

\begin{quote} \small\textit{
    "Los agentes son tan buenos como las herramientas que tienen."
} \\ 
\citep{langchain-docs-2024}.  \end{quote}

El uso de agentes se ha extendido en los últimos años, con una implementación
notable siendo la \emph{Generación Aumentada por Recuperación (RAG)}. Esta
arquitectura se sustenta sobre un agente conectado a una herramienta que
recolecta información de una base de datos, sustentando al LLM con conocimiento
específico de un campo o empresa y mejorando su precisión en entornos controlados.

La aparición de agentes IA abre habilita la oportunidad de realizar más
investigaciones en el campo de la cognición. La \emph{cognición} es una rama de la
informática que investiga el desarrollo de sistemas capaces de replicar
propiedades de la inteligencia humana como el razonamiento, la percepción, la
memoria, la planificación y la toma de decisiones. El cognitivismo clásico (la
primera aproximación hacia los algoritmos cognitivos) se ha estudiado desde
1956; sin embargo, la relación interdependiente entre múltiples módulos
necesarios para una arquitectura cognitiva ha planteado una limitación
bloqueante en investigaciones previas.

\begin{quote} \small\textit{ 
    "Tenemos círculos dentro de círculos. La dificultad central para la
    resolución de problemas eran los problemas de formulación limitada (PFL).
    Para enfrentarnos a ellos, recurrimos a la reestructuración.  Para abordar
    esto, recurrimos a la analogía y en su núcleo encontramos la resolución de
    un PFL como un componente crucial. El análisis y la formalización se han
    visto seriamente frustrados en todo este esfuerzo."
\citet{vervaeke1999naturalistic} } \end{quote}

A partir de los intentos de definir alguna forma de inteligencia cognitiva, han
surgido múltiples areas de estudio que evitan depender de un sistema
completamente inteligente. Por ejemplo, la resolución de problemas se ha
abordado utilizando IA clásica \citep{russell2016artificial}, STRIPS
\citep{fikes1971strips}, o PDDL \citep{aeronautiques1998pddl}. Aunque estos
enfoques han sido exitosos en múltiples aplicaciones, la llegada de agentes de
IA abre la puerta a retomar el estudio original de la cognición.

Gracias a los LLMs, es posible \emph{romper el bucle} de la restricción de
interdependencia al abordar el razonamiento como un problema de optimización
computable. Será aqui donde los agentes de IA permitirán que los LLMs se
integren en un sistema cognitivo, aportando una nueva aproximación a la cognición clasica.
En línea con estas arquitecturas, se define un \emph{agente cognitivo} como un
agente del cual emergen capacidades cognitivas, y que es capaz de interactuar,
aprender y modificar su comportamiento o entorno.


\section{GPS vs AGI}

El \emph{General Problem Solver (GPS)} ha sido estudiado en el campo de la
cognición desde 1959 con \citet{newell1959report}, quien introdujo el GPS como
un algoritmo hipotético o conjunto de técnicas que descomponen un problema en la
ejecución de una secuencia de operadores que, combinados de la manera adecuada,
pueden explorar multiples estados y subobjetivos del problema hasta alcanzar una
solución válida. Aunque se lograron avances en el diseño de un GPS, las
investigaciones sobre este tema se discontinuaron debido a las limitaciones de
la IA clásica y la cognición descritas en la Sección
\ref{sec:agents_and_cognition}.

Con propiedades similares al GPS, la \emph{Inteligencia Artificial General
(AGI)} es un nuevo enfoque basado en las técnicas de IA moderna y que preretende
entender, aprender y aplicar conocimientos en cualquier tarea cognitiva,
emulando las capacidades de un ser humano. Nótese que dado que la AGI se centra en
replicar la inteligencia humana en un sentido más amplio que una exploración de
estados, la capacidad de resolución de problemas emerge como parte de la
generalización del conocimiento humano, donde se requiere un nuevo marco que
interactúe con esta AGI para llevar esas capacidades a la realidad.

Es importante tener en cuenta que aunque la AGI no requiere necesariamente
interacción con el entorno, este término es comúnmente utilizado por marcos que
despliegan la AGI como su funcionalidad principal (otros nombres comunes
incluyen IA autónoma, agentes AGI, etc.). En adelante, nos referiremos a estas
arquitecturas como \emph{despliegues AGI}.

\begin{quote} \small\textit{
    "Demostrar que un sistema puede realizar un conjunto requerido de tareas en
    un nivel de rendimiento dado debería ser suficiente para declarar al sistema
    como AGI; el despliegue de dicho sistema en el mundo abierto no debería ser
    inherente a la definición de AGI."
\citet{morris2023levels} } \end{quote}

Ha habido múltiples implementaciones de despliegues de AGI. Algunas se centran
en especializar el conocimiento general en una aplicación específica, donde está
encapsulado dentro de un agente cognitivo que guía a la IA informándola sobre el
estado actual del entorno o las herramientas disponibles.

Un ejemplo de un despliegue especializado es \textsc{Voyager}. Este agente
utiliza una arquitectura basada en tres módulos: el \emph{currículo automático},
que describe el estado actual del agente y guarda información relevante; el
\emph{mecanismos de prompting iterativos}, que mantiene un bucle de
retroalimentación entre las acciones codificadas por la IA y la
retroalimentación obtenida; y la \emph{biblioteca de habilidades}, que permite a
la IA aprender y almacenar acciones previas y subobjetivos completados para
fomentar la reutilización de herramientas. Utilizando esta arquitectura,
\textsc{Voyager} demuestra la capacidad de jugar de manera autónoma al
videojuego \emph{Minecraft}, logrando múltiples objetivos solicitados.

\begin{quote} \small\textit{ 
    "VOYAGER exhibe un rendimiento superior en el descubrimiento de nuevos
    ítems, desbloqueo del árbol tecnológico de Minecraft, recorrido de diversos
    terrenos y aplicación de su biblioteca de habilidades aprendidas a tareas no
    vistas en un mundo recién creado. VOYAGER sirve como punto de partida para
    desarrollar agentes generalistas potentes sin necesidad de ajustar los
    parámetros del modelo." 
\citet{wang2023voyager} } \end{quote}

Otro proyecto relevante es \textsc{AutoGPT}. Este proyecto facilita el despliegue de
agentes autónomos para tareas menores. Maneja la gestión de tareas, la selección
de herramientas, múltiples técnicas de prompting y más. Para el despliegue de
agentes, \textsc{AutoGPT} proporciona lo que se conoce como la \textsc{Forge}, que
conecta automáticamente todos los mecanismos y servidores necesarios no solo
para empezar a ejecutar el agente, sino también para proporcionar al usuario
diversas herramientas para interactuar y depurar en tiempo real.

\begin{quote} \small\textit{
    "AutoGPT utiliza el concepto de apilamiento para llamarse recursivamente a
    sí mismo [...], usando este método y con la ayuda de GPT 3.5 y GPT 4, crea
    proyectos completos iterando sobre sus propios prompts." 
\citet{fezari2023gpt} } \end{quote}

Al igual que AutoGPT, los despliegues de AGI se están extendiendo a proyectos
para la asistencia de software en empresas (MetaGPT,
\cite{alexander2023metagpt}), despliegues autónomos (SuperAGI,
\cite{transformer2023superagi}), asistencia en el diseño-creatividad (AgentGPT,
\cite{reworkd2023agentgpt}), y más.

\section{Técnicas de Comportamiento para AGI's}

En secciones anteriores se ha discutido cómo las LLMs pueden ser utilizadas para
construir y desplegar AGIs. Sin embargo, existen múltiples maneras de modificar
o \emph{tunear} el comportamiento de una IA para que pueda implementarse con
éxito en agentes. A continuación, se destacan las técnicas clave en el estado
del arte para construir agentes a partir de LLMs:

\begin{itemize} \item \textbf{Tuneado (Fine-Tuning):} Todos los LLMs
    consisten en una o varias capas en una red neuronal basada en aprendizaje
    profundo. Estas capas contienen un conjunto de parámetros que definen el
    conocimiento o el comportamiento de la IA. Al entrenar un LLM ya estable con
    un conjunto de datos específicos de un campo, podemos mejorar la precisión de
    la IA con el conocimiento proporcionado y definir el formato y/o las
    directrices que debe seguir. Aunque este método obtiene mejores resultados
    que las siguientes técnicas, puede perder propiedades emergentes del LLM
    original y requiere un análisis previo del conjunto de datos proporcionado
    (sesgos, expectativas vs. resultados, limpieza de datos, etc.). En este
    campo, técnicas como el entrenamiento personalizado o el
    \textit{congelamiento} de capas pueden ser usadas para mejorar los
    resultados del ajuste fino.

\item \textbf{Ingeniería de Prompts (Prompting):} Sin modificar los parámetros del
    LLM, todavía podemos cambiar el comportamiento esperado introduciendo un
    \textit{prompt} diseñado para un objetivo específico que la IA recibirá como
    entrada y utilizará como directrices. Aunque este método no garantiza una mejor
    precisión en comparación con el uso de fine-tunning, no altera los parámetros del modelo
    y permite la definición de estructuras de razonamiento más complejas. Es importante
    señalar que, aunque este método puede generar riesgos de seguridad debido a un
    mal comportamiento de la IA, técnicas como la Cadena de Pensamiento (Chain of
    Thought, CoT), la Generación Aumentada por Recuperación (RAG) o los
    \textit{Few-Shot prompting} conducen a propiedades de razonamiento de alto nivel
    que no se han logrado con otros métodos. \cite{sahoo2024systematic}
    profundiza más en este campo.

\item \textbf{Composición:} Al utilizar tanto la ingeniería de prompts como los
    métodos de fine-tunning, es posible optimizar múltiples agentes dividiendo el
    comportamiento esperado en varios subobjetivos. A estos agentes se les suele
    llamar \textit{Expertos}, y reducen las alucinaciones de los LLMs distribuyendo
    la atención necesaria para completar una consulta dada en múltiples ejecuciones
    en lugar de una sola instancia. Algunos marcos de AGI, como AutoGen
    \cite{wu2023autogen}, están completamente basados en este método.

\item \textbf{Excitación de Características Interpretables:} Al usar LLMs, las
    características abstractas parecen tener una relación con patrones visibles
    dentro de los parámetros de la red neuronal. Estos parámetros pueden ser
    excitados (por ejemplo, aumentando la influencia de esos parámetros en la
    salida) para regular comportamientos relacionados con esa característica. La
    investigación realizada por \cite{viteri2024scaling} en este tema abre la puerta
    a usar este método en futuros diseños de agentes.  \end{itemize}


\section{Arquitecturas Cognitivas}

Independientemente de la metodología utilizada para construir un agente, la
composicion de mecanismos, herramientas y agentes constituye una
\emph{arquitectura cognitiva}.

Usando IA clásica y aprendizaje por refuerzo, \citet{laird2019soar} introdujeron
\textsc{Soar} como una arquitectura cognitiva unificada que integra varias
funciones cognitivas, como el aprendizaje, la memoria y la resolución de
problemas, en un único marco. \textsc{Soar} emplea un ciclo de decisión que
implica proponer, evaluar y seleccionar operadores en función del estado actual.

En la investigación contemporánea, las arquitecturas cognitivas han evolucionado
al incorporar más herramientas e integrar las capacidades de los LLMs como
mecanismos principales. \citet{wang2024survey} proporcionan una encuesta
exhaustiva de las principales arquitecturas para despliegues de AGI en los
últimos años, describiendo el modelo \textsc{PMPA} como un marco unificado que
abarca todas las arquitecturas estudiadas.

El modelo PMPA aborda cuatro temas principales que deben ser implementados por
la arquitectura cognitiva: 
\begin{itemize}

\item \textit{Perfil}: Define las
    principales directrices y reglas para los agentes implementados, orientados a
    los objetivos principales, la base de conocimientos y el comportamiento.  

\item \textit{Memoria}: Define la información y los datos obtenidos del entorno del
    agente y establece una estructura y mecanismo para recuperar, codificar y
    clasificar el conocimiento relevante.  

\item \textit{Planificación}: Define el
    mecanismo que permite al agente descomponer el objetivo principal en múltiples
    subobjetivos, emulando las capacidades de planificación humana.  

\item \textit{Acción}: Define el mecanismo que conecta o traduce las órdenes
    solicitadas por el agente en un conjunto de herramientas que interactuarán con
    el entorno o comportamiento del agente.  

\end{itemize}

Es importante señalar que, a diferencia de SOAR, este marco no prescribe métodos
específicos para conectar cada módulo. En su lugar, describe las propiedades
primarias que una arquitectura cognitiva debe poseer para ser viable en un
despliegue de AGI. Además del modelo PMPA, existen otros marcos de AGI, como el
Protocolo de Agentes-\citet{engineerfoundation2023ap}-, que proponen estándares
alternativos de API, comportamiento y módulos. Sin embargo, se necesitan más
avances en las arquitecturas cognitivas para establecer qué estándar será
finalmente adoptado.

\section {Estado del Arte en arquitecturas cognitivas}
\todo{Añadir información sobre arquitecturas más relevantes del estado del arte:
ReAct, VerifyAgain y/o expectativas sobre Q* de OpenAI}

% 5 niveles de AGI